#!/usr/bin/env python3
"""
ä¸Šä¸‹æ–‡åŠ è½½å™¨ â€” ä¸ºæ¯ä¸ª Pass ç»„è£…æ‰€éœ€çš„ä¸Šä¸‹æ–‡ã€‚

èŒè´£ï¼šè¯»å–æ–¹æ³•è®ºã€äººè®¾ã€ç»éªŒåº“ã€ç³»åˆ—ç»éªŒã€ç´ æï¼ŒæŒ‰ Pass éœ€æ±‚è£å‰ªåè¿”å›ã€‚

v2: æ–°å¢å…±äº«ä¸Šä¸‹æ–‡å±‚ + Pass 3.5 åå•†é—­ç¯æ‰€éœ€çš„ assemble æ–¹æ³•ã€‚
"""

import json
import re
from pathlib import Path
from datetime import datetime


class ContextLoader:
    """åŠ è½½å†™ä½œå¼•æ“æ‰€éœ€çš„å„ç±»ä¸Šä¸‹æ–‡ã€‚"""

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.wechat_dir = project_root / "wechat"

    # â”€â”€ åŸºç¡€åŠ è½½æ–¹æ³• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def load_methodology(self) -> str:
        """è¯»å–å®Œæ•´å†…å®¹æ–¹æ³•è®ºã€‚"""
        path = self.wechat_dir / "å†…å®¹æ–¹æ³•è®º.md"
        if path.exists():
            return path.read_text(encoding="utf-8")
        return ""

    def load_methodology_section(self, section_name: str) -> str:
        """æå–æ–¹æ³•è®ºä¸­çš„ç‰¹å®šç« èŠ‚ã€‚æŒ‰ ## æ ‡é¢˜åˆ‡åˆ†ã€‚"""
        full = self.load_methodology()
        if not full:
            return ""
        sections = full.split("\n## ")
        for s in sections:
            if s.startswith(section_name) or s.startswith(f" {section_name}"):
                return f"## {s}"
        return ""

    def load_persona(self, name: str) -> str:
        """è¯»å–äººè®¾æ¡£æ¡ˆã€‚"""
        path = self.wechat_dir / "äººè®¾" / f"{name}.md"
        if path.exists():
            return path.read_text(encoding="utf-8")
        return f"ï¼ˆæœªæ‰¾åˆ°äººè®¾æ¡£æ¡ˆï¼š{name}ï¼‰"

    def load_experience(self, max_entries: int = 20) -> str:
        """è¯»å–ç»éªŒåº“æœ€è¿‘ N æ¡ã€‚"""
        path = self.wechat_dir / "experience.jsonl"
        if not path.exists():
            return ""
        lines = path.read_text(encoding="utf-8").strip().split("\n")
        recent = lines[-max_entries:]
        result = []
        for line in recent:
            try:
                entry = json.loads(line)
                lesson = entry.get("lesson") or entry.get("rule", "")
                tags = entry.get("tags", [])
                source = entry.get("source", "")
                result.append(f"- [{', '.join(tags)}] {lesson}ï¼ˆæ¥æºï¼š{source}ï¼‰")
            except json.JSONDecodeError:
                continue
        return "\n".join(result) if result else ""

    def load_series_lessons(self, series_name: str) -> str:
        """è¯»å–ç³»åˆ—çº§ç»éªŒã€‚"""
        if not series_name:
            return ""
        path = self.wechat_dir / "å…¬ä¼—å·å·²å‘" / series_name / "lessons.md"
        if path.exists():
            return path.read_text(encoding="utf-8")
        return ""

    def load_series_articles_summary(self, series_name: str) -> str:
        """è¯»å–ç³»åˆ—å·²å‘æ–‡ç« çš„æ ‡é¢˜å’Œå¼€å¤´ï¼Œç”¨äºç»­æ°ã€‚"""
        if not series_name:
            return "ï¼ˆç‹¬ç«‹ç¯‡ï¼Œæ— ç³»åˆ—å¯¹æ¯”ï¼‰"
        series_dir = self.wechat_dir / "å…¬ä¼—å·å·²å‘" / series_name
        if not series_dir.exists():
            return ""
        result = []
        for md_file in sorted(series_dir.glob("*.md")):
            if md_file.name in ("lessons.md",) or md_file.name.endswith("-metrics.md"):
                continue
            content = md_file.read_text(encoding="utf-8")
            lines = content.strip().split("\n")
            preview = "\n".join(lines[:10])
            result.append(f"### {md_file.name}\n{preview}\n")
        return "\n".join(result) if result else "ï¼ˆæš‚æ— å·²å‘æ–‡ç« ï¼‰"

    def load_materials(self, topic_dir: Path) -> str:
        """è¯»å–é€‰é¢˜ç›®å½•ä¸‹çš„æ‰€æœ‰ç´ æã€‚"""
        materials_dir = topic_dir / "ç´ æ"
        if not materials_dir.exists():
            materials_dir = topic_dir

        result = []
        for md_file in sorted(materials_dir.rglob("*.md")):
            if md_file.name.startswith("article") or md_file.name.startswith("iteration_") or md_file.name in (
                "poll.md", "publish_guide.md", "review_report.md",
                "factcheck_report.md", "consensus.md",
                "verification_report.md", "description_options.md",
                "consensus_doc.md", "orphaned_recommendations.md",
            ):
                continue
            content = md_file.read_text(encoding="utf-8")
            result.append(f"\n--- ç´ æï¼š{md_file.name} ---\n{content}")

        return "\n".join(result) if result else "ï¼ˆæœªæ‰¾åˆ°ç´ ææ–‡ä»¶ï¼‰"

    # â”€â”€ å…±äº«ä¸Šä¸‹æ–‡å±‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def load_materials_summary(self, topic_dir: Path, max_chars: int = 3000) -> str:
        """æå– deep_research.md çš„æ ¸å¿ƒæ®µè½ï¼ˆæ ¸å¿ƒäº‹å®/æ—¶é—´çº¿/æ•°æ®è¡¨ï¼‰ï¼Œæˆªæ–­åˆ° max_charsã€‚"""
        dr_path = topic_dir / "ç´ æ" / "deep_research.md"
        if not dr_path.exists():
            # fallback: å¦‚æœæ²¡æœ‰ deep_research.mdï¼Œä»æ‰€æœ‰ç´ æå–æ‘˜è¦
            materials = self.load_materials(topic_dir)
            if materials and len(materials) > max_chars:
                return materials[:max_chars] + "\n\n[...ç´ ææ‘˜è¦å·²æˆªæ–­...]"
            return materials

        content = dr_path.read_text(encoding="utf-8")

        # ä¼˜å…ˆæå–æ ¸å¿ƒæ®µè½
        target_sections = ["æ ¸å¿ƒäº‹å®", "æ—¶é—´çº¿", "æ•°æ®è¡¨", "å…³é”®æ•°æ®", "å¤šæ–¹è§‚ç‚¹", "äº‰è®®ç‚¹"]
        extracted = []
        current_section = None
        current_lines = []

        for line in content.split("\n"):
            if line.startswith("## ") or line.startswith("### "):
                # ä¿å­˜ä¸Šä¸€æ®µ
                if current_section and any(kw in current_section for kw in target_sections):
                    extracted.append(f"{current_section}\n" + "\n".join(current_lines))
                current_section = line
                current_lines = []
            else:
                current_lines.append(line)

        # æœ€åä¸€æ®µ
        if current_section and any(kw in current_section for kw in target_sections):
            extracted.append(f"{current_section}\n" + "\n".join(current_lines))

        if extracted:
            summary = "\n\n".join(extracted)
        else:
            # æ²¡æœ‰åŒ¹é…çš„æ®µè½ï¼Œå–å‰ max_chars
            summary = content

        if len(summary) > max_chars:
            summary = summary[:max_chars] + "\n\n[...ç´ ææ‘˜è¦å·²æˆªæ–­...]"

        return summary

    def load_persona_summary(self, name: str, max_lines: int = 50) -> str:
        """è¯»å–äººè®¾æ‘˜è¦ï¼ˆå‰ max_lines è¡Œï¼‰ï¼Œç”¨äºå…±äº«ä¸Šä¸‹æ–‡ã€‚"""
        full = self.load_persona(name)
        lines = full.strip().split("\n")
        if len(lines) <= max_lines:
            return full
        return "\n".join(lines[:max_lines]) + "\n\n[...äººè®¾æ‘˜è¦å·²æˆªæ–­...]"

    def load_methodology_core(self, max_chars: int = 2000) -> str:
        """æå–æ–¹æ³•è®ºæ ¸å¿ƒï¼šé“å¾‹ + å†™ä½œè§„åˆ™ + Review é“å¾‹ã€‚"""
        full = self.load_methodology()
        if not full:
            return ""

        # æå–æ‰€æœ‰ ğŸ”º é“å¾‹æ ‡è®°çš„æ®µè½
        iron_rules = []
        for line in full.split("\n"):
            if "ğŸ”º" in line:
                iron_rules.append(line.strip())

        # æå–å…³é”®æ®µè½
        key_sections = []
        section_names = ["ç»“æ„ä¸å™äº‹è§„åˆ™", "æ’ç‰ˆä¸é£æ ¼è§„åˆ™", "æŠ€æœ¯åœˆè¡¨è¿°çº¢çº¿"]
        for sname in section_names:
            section = self.load_methodology_section(sname)
            if section:
                # åªå–å‰å‡ è¡Œä½œä¸ºæ‘˜è¦
                lines = section.strip().split("\n")
                key_sections.append("\n".join(lines[:15]))

        parts = []
        if iron_rules:
            parts.append("### é“å¾‹\n" + "\n".join(iron_rules))
        if key_sections:
            parts.append("\n".join(key_sections))

        result = "\n\n".join(parts)
        if len(result) > max_chars:
            result = result[:max_chars] + "\n\n[...æ–¹æ³•è®ºæ‘˜è¦å·²æˆªæ–­...]"

        return result

    def load_review_checklist(self) -> str:
        """ä»å†…å®¹æ–¹æ³•è®º.md æå–å®Œæ•´ Review checklistã€‚

        æå– 'ğŸ”º **Review é“å¾‹' å¼€å§‹åˆ°è¯¥ blockquote ç»“æŸçš„å†…å®¹ï¼Œ
        åŠ ä¸Š 'è‡ªæˆ‘ Review æ¡†æ¶ï¼šä¸‰å±‚æ°' æ®µè½ã€‚
        """
        full = self.load_methodology()
        if not full:
            return ""

        parts = []

        # 1. æå– Review é“å¾‹ blockquote
        in_review_blockquote = False
        review_lines = []
        for line in full.split("\n"):
            if "Review é“å¾‹" in line and "ğŸ”º" in line:
                in_review_blockquote = True
                review_lines.append(line)
                continue
            if in_review_blockquote:
                if line.startswith("> ") or line.strip() == ">":
                    review_lines.append(line)
                elif line.strip() == "":
                    # ç©ºè¡Œå¯èƒ½åœ¨ blockquote å†…
                    review_lines.append(line)
                else:
                    # blockquote ç»“æŸ
                    break

        if review_lines:
            parts.append("\n".join(review_lines))

        # 2. æå–ä¸‰å±‚æ°æ¡†æ¶
        three_layer = self.load_methodology_section("è‡ªæˆ‘ Review æ¡†æ¶ï¼šä¸‰å±‚æ°")
        if three_layer:
            parts.append(three_layer)

        return "\n\n".join(parts) if parts else ""

    def load_competitor_articles(self, topic_dir: Path, max_chars_per_article: int = 500,
                                  max_total_chars: int = 5000) -> str:
        """è¯»å–ç´ æä¸­å…¶ä»–å…¬ä¼—å·æ–‡ç« æ‘˜è¦ï¼Œç”¨äº Pass 3 ä»–æ°å¯¹æ¯”ã€‚

        è¯»å– ç´ æ/{å…¬ä¼—å·å}/ ä¸‹æ‰€æœ‰ md æ–‡ä»¶ï¼Œæ¯ç¯‡å–æ ‡é¢˜ + å‰ max_chars_per_article å­—ç¬¦ã€‚
        """
        materials_dir = topic_dir / "ç´ æ"
        if not materials_dir.exists():
            return "ï¼ˆæœªæ‰¾åˆ°ç«å“æ–‡ç« ç´ æï¼‰"

        result = []
        total_chars = 0

        for subdir in sorted(materials_dir.iterdir()):
            if not subdir.is_dir():
                continue
            # è·³è¿‡éå…¬ä¼—å·ç›®å½•ï¼ˆå¦‚ è‹±æ–‡æºï¼‰
            if subdir.name in ("è‹±æ–‡æº", "en_sources"):
                continue

            source_name = subdir.name
            for md_file in sorted(subdir.glob("*.md")):
                if total_chars >= max_total_chars:
                    break
                content = md_file.read_text(encoding="utf-8")
                # æå–æ ‡é¢˜
                title = md_file.stem
                lines = content.strip().split("\n")
                for line in lines:
                    if line.startswith("# "):
                        title = line[2:].strip()
                        break

                # å–æ‘˜è¦
                summary = content[:max_chars_per_article]
                if len(content) > max_chars_per_article:
                    summary += "\n[...å·²æˆªæ–­...]"

                entry = f"### æ¥æºï¼š{source_name}\n**{title}**\n{summary}\n"
                result.append(entry)
                total_chars += len(entry)

            if total_chars >= max_total_chars:
                result.append("\n[...æ›´å¤šç«å“æ–‡ç« å·²çœç•¥...]")
                break

        return "\n".join(result) if result else "ï¼ˆæœªæ‰¾åˆ°ç«å“æ–‡ç« ç´ æï¼‰"

    def build_shared_context(self, topic_dir: Path, persona_name: str) -> str:
        """æ„å»ºæ‰€æœ‰ Pass å…±äº«çš„ä¸Šä¸‹æ–‡å±‚ã€‚

        åŒ…å«ï¼šç´ ææ‘˜è¦ + äººè®¾æ‘˜è¦ + æ–¹æ³•è®ºæ ¸å¿ƒ + ç»éªŒåº“æœ€è¿‘10æ¡ã€‚
        æ€»å…±çº¦ 6-7k charsã€‚
        """
        parts = []

        # ç´ ææ‘˜è¦
        materials_summary = self.load_materials_summary(topic_dir)
        if materials_summary:
            parts.append(f"## ç´ ææ‘˜è¦\n\n{materials_summary}")

        # äººè®¾æ‘˜è¦
        persona_summary = self.load_persona_summary(persona_name)
        if persona_summary:
            parts.append(f"## æ‰§ç¬”äººè®¾æ‘˜è¦\n\n{persona_summary}")

        # æ–¹æ³•è®ºæ ¸å¿ƒ
        methodology_core = self.load_methodology_core()
        if methodology_core:
            parts.append(f"## æ–¹æ³•è®ºæ ¸å¿ƒ\n\n{methodology_core}")

        # ç»éªŒåº“ï¼ˆæœ€è¿‘10æ¡ï¼‰
        experience = self.load_experience(max_entries=10)
        if experience:
            parts.append(f"## ç»éªŒåº“ï¼ˆæœ€è¿‘10æ¡ï¼‰\n\n{experience}")

        return "\n\n---\n\n".join(parts) if parts else ""

    # â”€â”€ Pass 1-4 ä¸Šä¸‹æ–‡ç»„è£… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def assemble_pass1_context(self, topic_dir: Path, persona_name: str,
                                series_name: str = None) -> dict:
        """ç»„è£… Pass 1 å†™ä½œAgent æ‰€éœ€çš„å…¨éƒ¨ä¸Šä¸‹æ–‡ã€‚"""
        return {
            "SHARED_CONTEXT": self.build_shared_context(topic_dir, persona_name),
            "PERSONA": self.load_persona(persona_name),
            "PERSONA_NAME": persona_name,
            "DATE": datetime.now().strftime("%Y-%m-%d"),
            "EXPERIENCE": self.load_experience(),
            "SERIES_LESSONS": self.load_series_lessons(series_name),
            "MATERIALS": self.load_materials(topic_dir),
        }

    def assemble_pass2_context(self, topic_dir: Path, article_draft: str,
                                persona_name: str) -> dict:
        """ç»„è£… Pass 2 äº‹å®æ ¸æŸ¥Agent æ‰€éœ€çš„ä¸Šä¸‹æ–‡ã€‚"""
        return {
            "SHARED_CONTEXT": self.build_shared_context(topic_dir, persona_name),
            "ARTICLE_DRAFT": article_draft,
            "MATERIALS": self.load_materials(topic_dir),
        }

    def assemble_pass3_context(self, topic_dir: Path, article_factchecked: str,
                                persona_name: str, series_name: str = None) -> dict:
        """ç»„è£… Pass 3 å®¡è§†Agent æ‰€éœ€çš„ä¸Šä¸‹æ–‡ã€‚"""
        return {
            "SHARED_CONTEXT": self.build_shared_context(topic_dir, persona_name),
            "ARTICLE_FACTCHECKED": article_factchecked,
            "PERSONA": self.load_persona(persona_name),
            "EXPERIENCE": self.load_experience(),
            "SERIES_CONTEXT": self.load_series_articles_summary(series_name),
            "COMPETITOR_ARTICLES": self.load_competitor_articles(topic_dir),
            "REVIEW_CHECKLIST": self.load_review_checklist(),
        }

    def assemble_pass4_context(self, topic_dir: Path, article_draft: str,
                                factcheck_report: str, review_report: str,
                                latest_article: str, consensus_doc: str,
                                persona_name: str) -> dict:
        """ç»„è£… Pass 4 æ•´åˆAgent æ‰€éœ€çš„ä¸Šä¸‹æ–‡ã€‚"""
        return {
            "SHARED_CONTEXT": self.build_shared_context(topic_dir, persona_name),
            "ARTICLE_DRAFT": article_draft,
            "FACTCHECK_REPORT": factcheck_report,
            "REVIEW_REPORT": review_report,
            "CONSENSUS_DOC": consensus_doc,
            "LATEST_ARTICLE": latest_article,
        }

    # â”€â”€ Pass 3.5 åå•†é—­ç¯ä¸Šä¸‹æ–‡ç»„è£… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def assemble_write_respond_context(self, topic_dir: Path, review_report: str,
                                        article_factchecked: str, consensus_doc: str,
                                        persona_name: str) -> dict:
        """ç»„è£… Writing Agent å›åº” review çš„ä¸Šä¸‹æ–‡ã€‚"""
        return {
            "SHARED_CONTEXT": self.build_shared_context(topic_dir, persona_name),
            "REVIEW_REPORT": review_report,
            "ARTICLE_FACTCHECKED": article_factchecked,
            "CONSENSUS_DOC": consensus_doc,
            "PERSONA": self.load_persona(persona_name),
        }

    def assemble_fact_respond_context(self, topic_dir: Path, review_report: str,
                                       article_factchecked: str, consensus_doc: str,
                                       persona_name: str) -> dict:
        """ç»„è£… Fact Agent å›åº” review çš„ä¸Šä¸‹æ–‡ã€‚"""
        return {
            "SHARED_CONTEXT": self.build_shared_context(topic_dir, persona_name),
            "REVIEW_REPORT": review_report,
            "ARTICLE_FACTCHECKED": article_factchecked,
            "CONSENSUS_DOC": consensus_doc,
            "MATERIALS": self.load_materials(topic_dir),
        }

    def assemble_consensus_evaluate_context(self, topic_dir: Path, review_report: str,
                                              article_factchecked: str,
                                              consensus_doc: str,
                                              persona_name: str) -> dict:
        """ç»„è£… Review Agent è¯„ä¼°æ‰€æœ‰å›åº”çš„ä¸Šä¸‹æ–‡ã€‚"""
        return {
            "SHARED_CONTEXT": self.build_shared_context(topic_dir, persona_name),
            "REVIEW_REPORT": review_report,
            "ARTICLE_FACTCHECKED": article_factchecked,
            "CONSENSUS_DOC": consensus_doc,
        }

    def assemble_revision_context(self, topic_dir: Path, article_factchecked: str,
                                    consensus_doc: str, persona_name: str) -> dict:
        """ç»„è£… Writing Agent æŒ‰å…±è¯†æ‰§è¡Œå†™ä½œç±»ä¿®æ”¹çš„ä¸Šä¸‹æ–‡ã€‚"""
        return {
            "SHARED_CONTEXT": self.build_shared_context(topic_dir, persona_name),
            "ARTICLE_FACTCHECKED": article_factchecked,
            "CONSENSUS_DOC": consensus_doc,
            "PERSONA": self.load_persona(persona_name),
        }

    def assemble_fact_revision_context(self, topic_dir: Path, article_after_write_revision: str,
                                         consensus_doc: str, persona_name: str) -> dict:
        """ç»„è£… Fact Agent æŒ‰å…±è¯†æ‰§è¡Œäº‹å®ç±»ä¿®æ”¹çš„ä¸Šä¸‹æ–‡ã€‚"""
        return {
            "SHARED_CONTEXT": self.build_shared_context(topic_dir, persona_name),
            "ARTICLE": article_after_write_revision,
            "CONSENSUS_DOC": consensus_doc,
            "MATERIALS": self.load_materials(topic_dir),
        }

    def assemble_verification_context(self, article_before: str, article_after: str,
                                        consensus_doc: str, change_list: str,
                                        topic_dir: Path, persona_name: str) -> dict:
        """ç»„è£… Review Agent éªŒæ”¶çš„ä¸Šä¸‹æ–‡ã€‚"""
        return {
            "SHARED_CONTEXT": self.build_shared_context(topic_dir, persona_name),
            "ARTICLE_BEFORE": article_before,
            "ARTICLE_AFTER": article_after,
            "CONSENSUS_DOC": consensus_doc,
            "CHANGE_LIST": change_list,
        }

    # â”€â”€ Pass 5 è¿­ä»£æ±‚å¯¼ä¸Šä¸‹æ–‡ç»„è£… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def assemble_pass5_weakness_context(self, topic_dir: Path, article: str,
                                         persona_name: str) -> dict:
        """ç»„è£… Pass 5a è¯æ®ç¡¬åº¦å®¡è®¡çš„ä¸Šä¸‹æ–‡ã€‚"""
        return {
            "SHARED_CONTEXT": self.build_shared_context(topic_dir, persona_name),
            "ARTICLE": article,
            "MATERIALS": self.load_materials(topic_dir),
        }

    def assemble_pass5_research_context(self, topic_dir: Path, article: str,
                                          weakness: str, persona_name: str) -> dict:
        """ç»„è£… Pass 5b å®šå‘è°ƒç ”çš„ä¸Šä¸‹æ–‡ã€‚"""
        return {
            "SHARED_CONTEXT": self.build_shared_context(topic_dir, persona_name),
            "ARTICLE": article,
            "WEAKNESS_REPORT": weakness,
            "MATERIALS_SUMMARY": self.load_materials_summary(topic_dir),
        }

    def assemble_pass5_rewrite_context(self, topic_dir: Path, article: str,
                                         weakness: str, research: str,
                                         persona_name: str) -> dict:
        """ç»„è£… Pass 5c å®šå‘é‡å†™çš„ä¸Šä¸‹æ–‡ã€‚"""
        return {
            "SHARED_CONTEXT": self.build_shared_context(topic_dir, persona_name),
            "ARTICLE": article,
            "WEAKNESS_REPORT": weakness,
            "TARGETED_RESEARCH": research,
            "PERSONA": self.load_persona(persona_name),
        }

    def assemble_pass5_compare_context(self, topic_dir: Path, prev: str,
                                         curr: str, persona_name: str) -> dict:
        """ç»„è£… Pass 5d ç‰ˆæœ¬å¯¹æ¯”çš„ä¸Šä¸‹æ–‡ã€‚"""
        return {
            "SHARED_CONTEXT": self.build_shared_context(topic_dir, persona_name),
            "ARTICLE_PREV": prev,
            "ARTICLE_CURR": curr,
        }
