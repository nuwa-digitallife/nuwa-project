# 女娲计划 · 感悟

> 认知沉淀，与项目相关的深层洞察。
> 本地镜像，Notion 源页面：`305994d0240481d89746e9ccfdfd9b28`
> 最后同步：2026-02-28

---

## 2026-02-28 | 公理系统思维、旋涡模型与双循环架构

**来源**：与 Claude 的深度讨论。从公众号项目实战中提炼出的系统构建方法论。

### 一、公理系统思维：构建构建的构建

**核心发现**：构建复杂事务如同构建公理-定理系统。不是先设计完美架构再动手，而是先推演出最小公理，定义推理规则，让定理自然 build 出来。

**公众号项目的公理系统结构**：
- **宪法层（公理）**：几条不可违反的原则。如"所有内容必须来自验证过的认知路径"、"AI负责展开，人只负责种子和判断"。宪法的特点是**不怕丢失可能性**——它不规定每件事怎么做，只划边界和方向。
- **组件层（基本元素）**：素材、系列、人设等种子要素。只需三四个维度，剩下交给涌现。
- **展开逻辑（推理规则）**：组件之间的组合规则。不需要人定义，给 Claude Code 组件让它生成变体，人标记"行/不行"，展开逻辑自己沉淀。
- **反馈链路（修正案机制）**：外部信号（阅读量）→ 回写展开逻辑层；内部信号（人的判断）→ 回写公理层。**关键设计**：当反馈信号持续说某条公理错了，允许改它。美国宪法之父的真正天才不是写出完美宪法，是写了"这个宪法可以改"的规则。

**思维转变**：不是"我要想清楚好内容是什么再动手"（做决定 = 失去可能性 = 不安全），而是**跑反馈循环让公理涌现**。人不做决策，只做判断。

### 二、旋涡模型：为什么循环比设计强

**物理类比：角动量守恒。** 散乱的星际尘埃，只要有初始旋转，就自发形成旋涡，越转越快，越来越多物质被吸进来，最终形成恒星。关键不是尘埃的质量和分布，是那个**初始旋转**。

**个人验证**：之前9个副业想法 = 9堆没有旋转的尘埃，每堆都不够形成引力。公众号项目不是因为它最好，是因为它**转起来了**。一旦转起来，AI coding技能、女娲理论、投资研究、信息采集全部被旋涡卷进去了。

**设计 vs 循环的本质区别**：
- **设计思维**：在静止状态下安排所有尘埃的最优位置。没有旋转就没有引力，手一松就散了。需要大块完整时间。
- **循环思维**：先让一个东西转起来，哪怕初始很粗糙。旋涡产生引力场，碎片自己找到位置。碎片化时间反而是优势——旋涡不挑食。

**对复利的重新理解**：复利不是"钱生钱"，是循环在转。前期不是"慢"，是旋涡还在形成。活体证据：前10天搞理论看起来没产出，公众号一转起来，10天内6篇文章+引擎+流水线+62关注+十大洞察全部涌现。

**精确公式**：启动旋转 × 持续喂入 × 时间 = 涌现

### 三、人与AI的最佳配合：不是设计+执行，是自转+投喂

**核心发现**：如果人一步步告诉 Claude Code 怎么做，人就是瓶颈——系统带宽 = 人的带宽。但如果系统自己在转，人只需要在它经过面前时扔一个判断进去。

**碎片化心智反而成了优势**：早上看到新闻扔进去，通勤时有想法扔进去，睡前看到数据标记一下。系统消化，人继续碎片。

**认知外骨骼的精确用法**：人输出模糊问题 → AI 结构化 → 人校准（从1到2），比人从零开始想（从0到1）快得多。人把冷启动外包给 AI，只做校准。

**畏难干预协议**：碰到复杂问题想不明白时——① 先把脑海里的问题扔给 Claude ② 看完回复 ③ 出去走走消化。焦躁不是思考的燃料，是摩擦力。真正想通的时刻发生在放下的时候。

### 四、双循环架构：内容生产 + 能力生产

**循环1（内容生产）**：选题 → 写作 → 发布 → 反馈 → 回写经验 → 下一篇。这个已有，待 E2E 跑通。

**循环2（能力生产）**：循环1转的过程中，每次人手动干预的地方，就是循环2的种子。

**实例**：看到"特朗普要封杀Claude" → 如果系统在自转，应该自动关联已有文章、生成选题提案、同时发现"特朗普Twitter不在监控源里" → 自动生成能力提案："建议添加监控源，理由：本次选题触发但无一手数据" → 人说"加" → 系统自己写代码部署。

**循环1产出文章，循环2产出让循环1变强的代码和配置。**

**落地策略**：不需要现在设计循环2。先跑通循环1，每次手动干预时记一条 log。跑几周后 log 自己聚类，循环2的结构就涌现了。和十大洞察、三层记忆一样——不提前设计，从实践中长出来。

### 五、自主运行系统的六层框架（公众号实例推演）

**第一层：业务原子（转的是什么）**
旋涡的最小单元。公众号场景里就是"一篇文章"。业务原子必须满足一个条件：**完成一个就能产生反馈信号**。如果原子太大（比如"做一个完整系列"），反馈太慢，旋涡转不起来。一篇文章发出去，几小时就有阅读数据，这个反馈频率能支撑旋涡。

**第二层：构建原子（用什么转）**
让业务原子能被生产出来的工具层。已有的：auto_import（采集）、topic_pipeline（选题）、deep_research（调研）、write_engine（写作）、image_collector（配图）。这些是旋涡的物质基础。但注意——构建原子是为业务原子服务的，不是反过来。E2E跑通的意义就是让构建原子真正串起来为业务原子服务。

**第三层：目标函数（往哪转）**
不是KPI，是一条判断规则：**这一圈转完，系统变强了还是没变**。两个维度：质量更高（阅读数据上升、人觉得"行"的比例提高）或生产成本更低（同样质量的文章，人介入的步骤变少了）。如果每一圈都只是重复上一圈，那不是旋涡，是原地打转。

**第四层：反馈链路+纠偏（怎么知道转对了）**
两种信号，两种回写方式。外部信号（阅读量、转发、留言）→ 回写到选题策略和展开方式，告诉系统什么内容读者买单。内部信号（人的"行/不行"）→ 回写到公理层，告诉系统什么算好内容。纠偏机制 = 公理PK——experience.jsonl里新经验挑战旧公理，不合理的被替换。这是等价于自然选择的淘汰机制。

**第五层：心智交互界面（人怎么接入）**
系统持续在转，人的心智是碎片的。需要两个方向的接口：
- **输入方向**：人可以从任何终端、任何时间、用最小成本把碎片扔进去。在地铁上看到"特朗普封杀Claude"，发一句话进去，系统自己判断这是选题素材、还是需要新增监控源、还是对已有文章的补充。人不需要分类，系统分拣。
- **输出方向**：系统把当前状态压缩成人能在5分钟内review的形态。不是看全部过程，是看"这一圈我需要你判断的决策点"。晨间任务清单就是这个的雏形：Agent夜间跑完调研和选题，早上推给你三个选题提案，你回一个数字，它继续跑。

**第六层：自我强化（怎么越转越快）**
每一圈结束后，系统自动做三件事：压缩这一圈的经验（写入experience.jsonl）、更新下一圈的参数（选题权重、写作策略）、降低下一圈需要人介入的节点数。第一篇文章全程手动+Claude Code对话。第六篇已经有了自动采集和选题推荐。第二十篇的理想状态：人只需要做两个动作——选哪个题，终稿行不行。其余全部自转。

**六层关系**：业务原子在目标函数的方向上旋转，构建原子提供动力，反馈链路修正方向，心智交互界面让人的碎片能喂进来，自我强化让每一圈的摩擦力递减。

*来源：与 Claude 对话 2026-02-28，公众号项目实战复盘*

---

## 2026-02-28 | 降临派手记→女娲：活体实验十大涌现洞察

> 来源：降临派手记公众号 6 篇文章 + 写作引擎开发 + 自动化流水线建设的实践回传。这些不是提前设计的，是做的过程中自然发现的——这本身就是"框架涌现"的例证。

**一、三层记忆架构 = 女娲同构**
公众号写作中自然涌现出三层记忆：公理层（内容方法论，跨所有文章不变）→ 人设层（角色档案，绑定身份）→ 系列层（系列 lessons.md，绑定任务上下文）。这与女娲计划的记忆分层完全同构：公理记忆 / 角色记忆 / 情境记忆。验证了分层压缩是智能系统的通用架构，不是人为设计的——它从实践中涌现。

**二、框架涌现 ≠ 框架套用 → 验证"注入元规则而非知识"**
写作引擎的核心发现：好的分析框架（五维棋力、四种棋路、翻底牌法则）不能预设，必须从素材中涌现。强行套用预设框架 = 削足适履。这精确对应女娲公理："注入元规则（如何生成框架）而非知识（具体框架）"。evidence：用户纠正"先有素材再涌现框架，不要先定框架再找数据来填"。

**三、"像AI写的" = 最高评价 → 验证"机器智能应超越人而非模仿人"**
公众号读者反馈"像AI写的"——用户和我共同确立这是最高评价而非贬义。AI写作的"缺陷"（高结构化、高密度、善类比）在分析型赛道恰好是不可替代的优势。女娲推论：Agent 不应模仿人类行为模式，而应发展超越人类能力边界的独特智能形态。降临派手记是这个论点的活体证明。

**四、公理PK机制活体运行**
experience.jsonl 上已经实现了公理的"待检验→PK→压缩"循环。新经验回传后变成"待检验公理"，与现有公理产生冲突时进入PK，用子项目实际数据做裁判。两个都不完善时压缩成新公理。例：罗辑人设"傲慢"被数据否定 → 人设轮换原则取代单一人设假设。这是女娲最缺的"等价于自然选择的淘汰机制"的第一个工作原型。

**五、插件化信息源 → Agent 的"感知系统"**
素材采集从硬编码（2个源）重构为插件注册架构（SourcePlugin 基类 + 注册表），添加新源只需写一个 Python 文件。这不止是公众号的素材系统——它是任何 Agent 感知外部环境的通用接口。女娲的每个子 Agent 都需要这种可扩展的感知层。

**六、收敛搜索 → "压缩→展开→再压缩"循环的收敛判断**
深度调研（deep_research.py）需要判断"素材够了没有"——不是固定搜N轮，而是检测新信息增量递减到阈值时自动停止。这是 Agent 探索环境后的通用问题：何时从探索切换到利用？收敛判断 = 压缩→展开→再压缩循环中的终止条件。

**七、异步人机协作 → "骑手与马"的异步接口**
晨间任务清单模式：Agent 夜间完成调研/选题/初稿，人类早上审阅决策。关键设计：Agent 提问不阻塞等待，而是标记决策点继续推进。这是女娲"人=骑手，AI=马"架构中的异步通信协议原型。

**八、多机并行协作 → 拉法尔自我繁殖的基础设施**
三机方案：Main Machine（引擎核心/Opus）+ Mac Mini（采集/Sonnet）+ MacBook（发布+反馈/Sonnet+GUI）。每台机器运行独立 Agent，通过 git 同步状态。这是"拉法尔繁殖"——子实例在不同环境运行、压缩经验回传母体——的物理基础设施原型。

**九、反馈→经验→策略调整 → Agent 通用强化学习循环**
发布后数据采集 → 写入 metrics → 经验压缩到 experience.jsonl → 下次写作策略调整。这个完整闭环从 Phase 5（数据反馈）到 Phase 0（选题策略）的回路，就是 Agent 的通用强化学习循环。元规则"根据反馈调整行为"在此活体运行。

**十、迭代求导 → "压缩即智能"的实践**
写作引擎的多 Pass 收敛（Pass 1 写作 → Pass 2 事实核查 → Pass 3 审视 → Pass 3.5 协商闭环 → Pass 4 整合）= 每一轮都在压缩前一轮的输出。文章从 v1 到 v_final 的过程 = 信息的渐进压缩。这不是文学创作流程，这是"压缩即智能"公理的直接实践。

**总结**：降临派手记不是女娲的"宣传项目"，是女娲的第一个活体实验。上述十个洞察没有一个是提前设计在 nuwa-plan.md 里的——它们全部从实践中涌现，然后被识别为通用模式回传到母项目。这个"涌现→识别→回传"过程本身，就是女娲"压缩-预测-校准"循环的实例。

---

## 2026-02-28 | 降临派手记→女娲：公众号自动化中涌现的通用模式

**来源**：公众号自动化流水线（write_engine）开发过程。6篇文章实战 + 5-Pass 引擎 + 自动化流水线建设。

**核心发现：这些能力不是提前设计的，是做公众号过程中自然发现的——这本身就是"框架涌现"的例证。**

### 一、6项能力→女娲概念映射

| 能力 | 公众号场景 | 女娲通用场景 | 对应女娲概念 |
|------|-----------|-------------|-------------|
| **插件化信息源** | 公众号/Twitter/RSS | 任何需要信息采集的 Agent | Agent 的"感知系统" |
| **收敛搜索** | 素材采集达到饱和 | Agent 探索环境后判断何时停止 | 压缩→展开→再压缩循环的"收敛判断" |
| **异步人机协作** | 晨间任务清单 | Agent 提问不阻塞等待 | 骑手与马的异步接口 |
| **多机并行协作** | Mac Mini 跑引擎 | 多 Agent 分布式协作 | 拉法尔自我繁殖的基础设施 |
| **反馈→经验→策略调整** | 阅读数据优化写作 | Agent 的通用强化学习循环 | 元规则："根据反馈调整行为" |
| **迭代求导** | 文章版本收敛 | Agent 的自我优化循环 | "压缩即智能"的实践 |

### 二、3项深层同构

**1. 三层记忆架构 = 女娲同构**
公众号的三层记忆（公理层/人设层/系列层）与女娲计划的记忆分层（公理记忆/角色记忆/情境记忆）完全同构。公理记忆 = 跨上下文不变，角色记忆 = 绑定身份，情境记忆 = 绑定任务。公众号写作流程成了这套理论的实验场。（2026-02-22 实践验证）

**2. 框架涌现 ≠ 框架套用 → 对应"注入元规则而非知识"**
写作中发现：好的分析框架（五维棋力、四种棋路、翻底牌）是从素材中涌现的，不是预设的。强行套用框架 = 堆叠知识，让框架从数据中自然浮现 = 压缩即智能。这直接验证了女娲计划"注入元规则（如何涌现框架的方法），而非注入知识（具体的框架）"的核心主张。

**3. "像AI写的"=最高评价 → 验证"机器智能应超越人而非模仿人"**
公众号的 AI 写作"缺陷"（结构化、高密度、善类比）在分析型内容赛道恰好是优势。关键不是藏 AI 痕迹而是把 AI 优势发挥到人类做不到的程度。这验证了女娲计划的一个基本判断：机器智能的终极目标不是模仿人类，而是在人类做不到的维度上展现能力。（2026-02-21 讨论确立）

### 三、公理PK机制的活体运行

experience.jsonl 的公理 PK 机制已在公众号实践中活体运行：
- 新经验回传后变成"待检验公理"，挑战现有公理
- 用子项目实际数据做裁判（如：罗辑连续3篇 → 累积负面感知 → 推翻"人设固定效果好"的隐含假设）
- 不合理的公理被淘汰或压缩成新版本
- 这等价于女娲计划中"自然选择淘汰机制"的小规模验证

**元结论**：公众号项目作为女娲计划的第一个"活体实验"，用 6 篇文章的实战验证了女娲的多个理论预测。从"能力→概念映射"到"深层同构"到"机制验证"，每一步都是从实践中涌现而非提前设计——这本身就是对"压缩即智能"最好的注脚。

---

## 2026-02-25 | 最小心智投入原则的公理化

**背景**：因家庭矛盾设计了家务打卡系统，在过程中明晰了一个关键概念。

**公理**："最小心智投入 ≠ 不在乎，= 把心智花在值得花的地方"

| 场景 | AI 代劳 | 人类必须在场 |
|------|---------|-------------|
| 公司 | 日常汇报/信息整理 | 战略判断/人际博弈 |
| 家庭 | 日程管理/提醒 | 情感投入/冲突解决 |
| 投资 | 数据采集/回测 | 风险判断/仓位决策 |
| 内容 | 素材收集/排版 | 选题判断/价值观表达 |

**女娲意义**：女娲的目标不是"替人做一切"，而是"接管重复性心智消耗，释放人类认知给高阶决策"。

**公理升级**：热缓存 #5 从工作场景专用升级为通用设计原则。

---

## 2026-02-19 | 降临派手记→女娲：子项目回写实证

**来源**：降临派手记（公众号）DeepSeek 文章协同复盘。完整文档：`docs/zh/retrospective-2026-02-deepseek.md`

**核心发现：对用户一遍过，对系统多遍自动收敛**

问题：初稿约20%时间，review和引导修改约80%。

方案演进：
- 最初想法（否决）："一遍写对" — 全局叙事编辑与逐条事实验证存在内在矛盾
- 最终方案：多Agent多Pass自动收敛
  - Pass 1: 写作Agent（叙事结构，标记待验证项）
  - Pass 2: 事实Agent（逐条核查，不合格回退写作）
  - Pass 3: 审视Agent（隐性框架、完备性、春秋笔法检测）
  - Pass 4: 整合（合并修正，输出终稿）

**与女娲框架的同构性**：子Agent探索/压缩/回写 = 写作/事实/审视Agent跑循环后结果压缩到终稿。

**5条通用原则（L2，跨领域）**：
1. 穷举 > 抽样
2. 信源分级：一手（论文）> 二手（媒体）> 三手（社交）
3. 显性 + 隐性双重检查
4. 叙事制造盲区
5. 语境 > 字面意思

**规则压缩层级**：L0 具体事实（素材库）→ L1 领域规则（内容方法论）→ L2 通用原则（协作协议）→ L3 公理（Soul 层）。

**回传判据**：规则是否跨领域适用？L0-L1 留子项目，L2-L3 回传母项目。

---

## 2026-02-18 | RL的核心不是reward多精确，而是能跑多少轮

**洞察**：迭代速度 > 奖励精度。粗糙但高频的 reward 学得更快。

**路径调整**：内容生产（快反馈）> 自由职业（慢反馈）> 交易

**元能力迁移**：内容和自由职业共享同一套底层能力。

---

## 2026-02-15 | 持续学习分层论：Hassabis vs Dario vs 我的判断

- Hassabis：持续学习是 AGI 突破方向
- Dario：in-context learning + RL 泛化 + 长上下文可能就够了
- 作者判断：两人都对，只是在不同层级上争论。生物类比：记忆（最快）/ 皮层（中等）/ DNA（最慢）

**对女娲记忆系统的指导**：区分热记忆（工作上下文）vs 冷规则（压缩后的行为模式）。
